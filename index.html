<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="en">

<head>
  <meta http-equiv='Content-Type' content='text/html; charset=us-ascii'>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  <title>Som Sagar</title>
  <link rel="stylesheet" href="styles.css">
  <link rel='icon' type='image/jpg' href='images/profile_old.png'>
</head>

<!-- Simple Dark/Light Mode Toggle -->
<div id="theme-toggle-btn" title="Toggle dark/light mode">
  <span class="material-icons" id="themeToggleIcon">light_mode</span>
</div>


  <div id='videoModal' class='modal'>
    <div class='modal-content'>
      <span class='close-btn' onclick='closeModal()'>&times;</span>
      <video id='modalVideo' controls>
        <source src='' type='video/mp4'>
        Your browser does not support the video tag.
      </video>
    </div>
  </div>

  <br/>
  <table style='max-width: 900px; width: 90%; margin: auto;' border='0' cellspacing='0' cellpadding='0'>
    <tr>
      <td>
        <div class="main-layout">

            <div class="bio-name">
              <p>
                <name>Som Sagar</name><br>
                <span style="font-size: 16px; color: #444;">ssagar6 at asu dot edu</span>
              </p>
            </div>
          
          <div class="left-column">
            <div class="bio-text">
              <p align='justify'>Hi! I am a third-year computer science PhD student at Arizona State University advised by Prof. <a href='https://www.ransalu.com/'>Ransalu Senanayake</a> and affiliated with the <a href='https://ransml.github.io/lens-lab/'>Laboratory for Learning Evaluation and Naturalization of Systems (LENS Lab)</a>. My research focuses on developing robust and adaptable machine learning models, with an emphasis on reinforcement learning and uncertainty estimation. I aim to create systems that can effectively handle distribution shifts and new information in dynamic environments. By integrating foundational models, reinforcement learning, and real-world applicability, I seek to enhance model interpretability, improve generalization, and optimize decision-making processes in AI systems.</p>
              <p align='justify'>Previously, I received a B.Tech Honors in Computer Science from the Indian Institute of Information Technology (IIIT), Kottayam.</p>
              <p align='justify'>I am originally from Kerala, India, and outside of research, I enjoy spending time outdoors, especially playing soccer, hiking, and swimming.</p>
              <p align='justify'>I'm always happy to connect about research, collaborate on ideas, or share advice. Please feel free to get in touch!</p>
            </div>
            
            <div class="bio-links">
              <p>
                <a href='data/Sagar_CV.pdf' class='btn' target="_blank"> <span class='material-icons'>picture_as_pdf</span> CV</a>
                <a href='https://scholar.google.com/citations?user=qWxEX0QAAAAJ&hl=en' class='btn' target='_blank'> <span class='material-icons'>school</span> Google Scholar</a>
                <a href='https://www.linkedin.com/in/somsagar/' class='btn' target='_blank'> <span class='material-icons'>business</span> LinkedIn</a>
                <a href='https://github.com/somsagar07' class='btn' target='_blank'> <span class='material-icons'>code</span> GitHub</a>
                <a href='https://www.notion.so/som-sagar/Welcome-to-my-blog-12a8157ad43a80028d67d1942283f9ce' class='btn' target='_blank'> <span class='material-icons'>book</span> Blog</a>
              </p>
            </div>
          </div> <div class="profile-pic-container">
            <img src='images/profile.jpg' alt='Profile Picture'>
          </div>

        </div>
        <h2>News</h2>
        <div class="news-scroll-container">
          <table width='100%' border='0' cellspacing='0' cellpadding='2'>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Sept '25</span></td>
              <td width='90%' valign='top'>Our paper "<a class='news-item-title' href='https://arxiv.org/abs/2506.23725' target='_blank'>PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?</a>" was accepted to NeurIPS 2025.</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Jun '25</span></td>
              <td width='90%' valign='top'>Our paper "<a class='news-item-title' href='https://arxiv.org/abs/2409.10733' target='_blank'>Trustworthy Explanations for Robot Behaviors</a>" was accepted to IROS 2025.</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>May '25</span></td>
              <td width='90%' valign='top'>Joining <a class='news-item-title' href="https://www.linkedin.com/company/linkedin/" target='_blank'><img src="images/LinkedIn_logo.png" alt="LinkedIn Logo" style="height: 1em; vertical-align: middle; margin-right: 3px;">LinkedIn</a> as a research intern this summer.</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Apr '25</span></td>
              <td width='90%' valign='top'>Our paper "<a class='news-item-title' href='https://arxiv.org/abs/2408.13438' target='_blank'>Explainable Concept Generation through Vision-Language Preference Learning for Understanding Neural Networks' Internal Representations</a>" was accepted to ICML 2025.</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Dec '24</span></td>
              <td width='90%' valign='top'>Presented four workshop papers at NeurIPS 2024.</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Apr '24</span></td>
              <td width='90%' valign='top'>Our ICML 2024 paper "<a class='news-item-title' href='https://arxiv.org/abs/2406.07145' target='_blank'>Failures Are Fated, But Can Be Faded: Characterizing and Mitigating Unwanted Behaviors in Large-Scale Vision and Language Models</a>" was accepted as a <span class='news-highlight-red'>spotlight (top 3.5%)</span>.</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Aug '23</span></td>
              <td width='90%' valign='top'>Started my PhD in Computer Science at Arizona State University, joining the LENS Lab.</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>May '23</span></td>
              <td width='90%' valign='top'>Graduated from IIIT Kottayam with a B.Tech (Honors) in Computer Science.</td>
            </tr>
          </table>
        </div>


        <table style='width: 100%; table-layout: fixed;' border='0' cellspacing='0' cellpadding='5' class='publications-table'>

          <h2>Research</h2>
          <p>Please see my CV or Google Scholar for a full list of work.</p>

          <tr>
            <td width="20%" class="pub-image">
                <img src="images/Neurips_PAC.png" width="130"> 
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?</papertitle><br>
              Atharva Gundawar*, <b>Som Sagar*</b>, Ransalu Senanayake<br>
              <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2025

              <div class="description">
                We introduce PAC Bench, a benchmark designed to evaluate the capability of foundational models in understanding and predicting prerequisite conditions necessary for the successful execution of robot manipulation tasks. 
              </div>

              <a href="https://arxiv.org/abs/2506.23725" class="btn btn-publication" target="_blank"><span class="material-icons">picture_as_pdf</span> PDF</a>
              <!-- <a class="btn btn-publication" onclick="openModal('videos/BaTCAVe Video.mp4')"><span class="material-icons">play_circle</span> Video</a> -->
              <a href="https://huggingface.co/Pacbench" class="btn btn-publication" target="_blank"><span class="material-icons">dataset</span> Dataset</a>
              <a href="javascript:void(0)" class="btn btn-publication" onclick="toggleBib('bib1')"><span class="material-icons">format_quote</span> BibTeX</a>
              <div id="bib1" class="bibtex"><pre>@article{gundawar2025pac,
            title={PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?},
            author={Gundawar, Atharva and Sagar, Som and Senanayake, Ransalu},
            journal={arXiv:2506.23725},
            year={2025}
          }</pre></div>
            </td>
          </tr>

          <tr>
            <td width="20%" class="pub-image">
              <img src="images/IROS_1.png" width="150">
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>Trustworthy Explanations for Robot Behaviors</papertitle><br>
             <b>Som Sagar*</b>, Aditya Taparia*, Harsh Mankodiya, Pranav Bidare, Yifan Zhou, Ransalu Senanayake<br>
              <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2025

              <div class="description">
                We introduce BaTCAV, a Bayesian TCAV framework with uncertainty estimations that enhances the interpretability of robotic actions across both simulation platforms and real-world robotic systems.
              </div>

              <a href="https://arxiv.org/abs/2409.10733" class="btn btn-publication" target="_blank"><span class="material-icons">picture_as_pdf</span> PDF</a>
              <a class="btn btn-publication" onclick="openModal('videos/BaTCAVe Video.mp4')"><span class="material-icons">play_circle</span> Video</a>
              <a href="https://github.com/aditya-taparia/BaTCAVe" class="btn btn-publication" target="_blank"><span class="material-icons">code</span> Code</a>
              <a href="javascript:void(0)" class="btn btn-publication" onclick="toggleBib('bib1')"><span class="material-icons">format_quote</span> BibTeX</a>
              <div id="bib1" class="bibtex"><pre>@article{sagar2024trustworthy,
            title={Trustworthy Conceptual Explanations for Neural Networks in Robot Decision-Making},
            author={Sagar, Som and Taparia, Aditya and Mankodiya, Harsh and Bidare, Pranav and Zhou, Yifan and Senanayake, Ransalu},
            journal={arXiv preprint arXiv:2409.10733},
            year={2024}
          }</pre></div>
            </td>
          </tr>


          <tr>
            
            <td width="20%" class="pub-image">
              <img src="images/ICML_2.jpg" width="150">
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>Explainable Concept Generation through Vision-Language Preference Learning for Understanding Neural Networks' Internal Representations</papertitle><br>
              Aditya Taparia, <b>Som Sagar</b>, Ransalu Senanayake<br>
              <em>International Conference on Machine Learning (ICML)</em>, 2025

              <div class="description">
                We propose a Reinforcement Learning-based Preference Optimizing exploration (RLPO) method designed to generate explainable states within a classification model, enabling the discovery of interpretable states that may be difficult or impossible for humans to identify.
              </div>

              <a href="https://arxiv.org/abs/2408.13438" class="btn btn-publication" target="_blank"><span class="material-icons">picture_as_pdf</span> PDF</a>
              <a class="btn btn-publication" onclick="openModal('videos/GenXAI Video.mp4')"><span class="material-icons">play_circle</span> Video</a>
              <a href="https://github.com/aditya-taparia/RLPO" class="btn btn-publication" target="_blank"><span class="material-icons">code</span> Code</a>
              <a href="javascript:void(0)" class="btn btn-publication" onclick="toggleBib('bib2')"><span class="material-icons">format_quote</span> BibTeX</a>
              <div id="bib2" class="bibtex"><pre>@article{taparia2024explainable,
                title={Explainable Concept Generation through Vision-Language Preference Learning for Understanding Neural Networks' Internal Representations},
                author={Taparia, Aditya and Sagar, Som and Senanayake, Ransalu},
                journal={arXiv preprint arXiv:2408.13438},
                year={2024}
              }</pre></div>
            </td>
          </tr>

          <tr>
            <td width="20%" class="pub-image">
              <img src="images/RSS_ood.png" width="150">
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>From Mystery to Mastery: Failure Diagnosis for Improving Manipulation Policies</papertitle><br>
              <b>Som Sagar</b>, Jiafei Duan, Sreevisakh V, Yifan Zhou, Heni Ben'Amor, Dieter Fox, Ransalu Senanayake<br>
              <em>Robotics: Science and Systems (RSS) Workshop on Out-of-Distribution Generalization in Robotics</em>, 2025
              <div class="description">
                We propose a systematic framework for diagnosing failure modes in robot manipulation tasks under unseen environmental conditions. It enables robust identification of failure patterns to improve generalization in robotic systems.
              </div>

              <a href="https://arxiv.org/pdf/2412.02818" class="btn btn-publication" target="_blank"><span class="material-icons">picture_as_pdf</span> PDF</a>
              <a href="https://github.com/somsagar07/FailureShiftRL" class="btn btn-publication" target="_blank"><span class="material-icons">language</span> Website</a>
              <a href="javascript:void(0)" class="btn btn-publication" onclick="toggleBib('bib3')"><span class="material-icons">format_quote</span> BibTeX</a>
              <div id="bib3" class="bibtex"><pre>@inproceedings{sagar2024mystery,
            title={From Mystery to Mastery: Failure Diagnosis for Improving Manipulation Policies},
            author={Sagar, Som and Duan, Jiafei and Vasudevan, Sreevisakh and Zhou, Yifan, Ben'Amor, Heni and Fox, Dieter and Senanayake, Ransalu},
            booktitle={RSS Workshop on Out-of-Distribution Generalization in Robotics},
            year={2025}
          }</pre></div>
            </td>
          </tr>

          <tr>
            <td width="20%" class="pub-image">
              <img src="images/ICML_1.png" width="150">
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>Failures Are Fated, But Can Be Faded: Characterizing and Mitigating Unwanted Behaviors in Large-Scale Vision and Language Models</papertitle><br>
              <b>Som Sagar</b>, Aditya Taparia, Ransalu Senanayake<br>
              <em>International Conference on Machine Learning (ICML)</em>, 2024
              <span style="color: #EF5350; font-weight: 600;"> &mdash; spotlight (top 3.5%)</span>
              <div class="description">
                We introduce a framework that maps the failure landscape of large vision and language models, addressing their shortcomings by realigning model behavior with human preferences—whether stylistic or ethical—to mitigate failures.
              </div>

              <a href="https://arxiv.org/abs/2406.07145" class="btn btn-publication" target="_blank"><span class="material-icons">picture_as_pdf</span> PDF</a>
              <a class="btn btn-publication" onclick="openModal('videos/Failure Video.mp4')"><span class="material-icons">play_circle</span> Video</a>
              <a href="https://github.com/somsagar07/FailureShiftRL" class="btn btn-publication" target="_blank"><span class="material-icons">code</span> Code</a>
              <a href="javascript:void(0)" class="btn btn-publication" onclick="toggleBib('bib4')"><span class="material-icons">format_quote</span> BibTeX</a>
              <div id="bib4" class="bibtex"><pre>@inproceedings{sagar2024failures,
            title={Failures are fated, but can be faded: characterizing and mitigating unwanted behaviors in large-scale vision and language models},
            author={Sagar, Som and Taparia, Aditya and Senanayake, Ransalu},
            booktitle={Proceedings of the 41st International Conference on Machine Learning},
            pages={42999--43023},
            year={2024}
          }</pre></div>
            </td>
          </tr>

          <tr>
            <td width="20%" class="pub-image">
              <img src="images/Neurips_Behaviour.png" width="150">
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>ExpressivityArena: Can LLMs Express Information Implicitly?</papertitle><br>
              Joshua Tint, <b>Som Sagar</b>, Aditya Taparia, Caleb Liu, Kelly Raines, Bimsara Pathiraja, Ransalu Senanayake<br>
              <em>NeurIPS Workshop on Behavioral Machine Learning</em>, 2024

              <div class="description">
                We introduce ExpressivityArena, a framework designed to evaluate the expressiveness of large language models (LLMs), enabling systematic assessment of their ability to convey nuanced and implicit information across various contexts.
              </div>

              <a href="https://arxiv.org/abs/2411.08010" class="btn btn-publication" target="_blank"><span class="material-icons">picture_as_pdf</span> PDF</a>
              <a href="javascript:void(0)" class="btn btn-publication" onclick="toggleBib('bib5')"><span class="material-icons">format_quote</span> BibTeX</a>
              <div id="bib5" class="bibtex"><pre>@inproceedings{tint2024expressivityarena,
            title={ExpressivityArena: Can LLMs Express Information Implicitly?},
            author={Tint, Joshua and Sagar, Som and Taparia, Aditya and Liu, Caleb and Raines, Kelly and Pathiraja, Bimsara and Senanayake, Ransalu},
            booktitle={NeurIPS 2024 Workshop on Behavioral Machine Learning},
            year={2024}
          }</pre></div>
            </td>
          </tr>

          <tr>
            <td width="20%" class="pub-image">
              <img src="images/Neurips_redteaming.png" width="150">
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>LLM-Assisted Red Teaming of Diffusion Models through “Failures Are Fated, But Can Be Faded”</papertitle><br>
              <b>Som Sagar</b>, Aditya Taparia, Ransalu Senanayake<br>
              <em>NeurIPS Workshop on Red Teaming GenAI</em>, 2024

              <div class="description">
                This extension of the Failures Are Fated work demonstrates how we use LLM-assisted methods to generate rewards and states in diffusion models, and incorporate RL search strategies to optimize the discovery process.
              </div>

              <a href="https://arxiv.org/abs/2410.16738" class="btn btn-publication" target="_blank"><span class="material-icons">picture_as_pdf</span> PDF</a>
              <a href="javascript:void(0)" class="btn btn-publication" onclick="toggleBib('bib6')"><span class="material-icons">format_quote</span> BibTeX</a>
              <div id="bib6" class="bibtex"><pre>@inproceedings{sagar2024llm,
            title={LLM-Assisted Red Teaming of Diffusion Models through “Failures Are Fated, But Can Be Faded”},
            author={Sagar, Som and Taparia, Aditya and Senanayake, Ransalu},
            booktitle={Red Teaming GenAI: What Can We Learn from Adversaries?},
            year={2024}
          }</pre></div>
            </td>
          </tr>

        </table>
      </td>
    </tr>
  </table>

  <br>

  <center>
    <p style="font-size: small;">Website template from <a href="https://github.com/aditya-taparia/aditya-taparia.github.io">here.</a></p>
  </center>
  

  <script>
    function toggleBib(id) { document.getElementById(id).classList.toggle('show'); }
    function openModal(src) {
      var modal = document.getElementById('videoModal');
      var videoEl = document.getElementById('modalVideo');
      videoEl.querySelector('source').src = src; videoEl.load(); modal.style.display = 'flex';
    }
    function closeModal() {
      var modal = document.getElementById('videoModal');
      var videoEl = document.getElementById('modalVideo');
      videoEl.pause(); modal.style.display = 'none';
    }
    document.getElementById('videoModal').addEventListener('click', function (e) {
      if (e.target === this) closeModal();
    });

  const toggleBtn = document.getElementById('theme-toggle-btn');
  const toggleIcon = document.getElementById('themeToggleIcon');

  // Apply stored preference
  if (localStorage.getItem('theme') === 'dark') {
    document.body.classList.add('dark');
    toggleIcon.textContent = 'dark_mode';
  }

  toggleBtn.addEventListener('click', () => {
    document.body.classList.toggle('dark');
    const isDark = document.body.classList.contains('dark');
    toggleIcon.textContent = isDark ? 'dark_mode' : 'light_mode';
    localStorage.setItem('theme', isDark ? 'dark' : 'light');
  });
  </script>
</body>

</html>
